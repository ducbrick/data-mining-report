***Finding similar items***

# Introduction
## What is "finding similar items"
General infos
## What is "similarity", how are items considered similar
List & explain more deeply some criteria/models of similarity measurement
## Why does it matter
General infos
It matters because many real world problem require finding similar items ğŸ˜¥  
Many higher-level algorithms like clustering or classification depend on accurate item similarity measurement. wtf do I even write here :( 

## Specific/real-world applications

### Recommendation system
+ Popularly used in many domains
+ "Users who viewed this items also viewed"
+ "Similar items"
+ Directly retrieves recommendations similar to user's preferred items
    + Visually similar items
    + Name, description, metadata
    + Songs: genre, artist, tempo, key, time signature, phrases, etc.
    + Movies: topic, genre, actors, directors, viewers, etc.
    + Other extracted data
+ Indirectly retrieves recommendations through other similar users
    + Personal informations: age, gender, location, preferences, demographic, etc.
    + User interaction: Visited items, purchased items, clicks, etc.

### Plagiarism/duplicate detection
+ Determine the level of similarity between a document and an existing one
+ Textual similarity
    + Lexical similarity: simple exact/near exact text matching
    + Structure/syntactic similarity: structure/ordering of words, sentences or paragraphs
    + Sematic similarity: meaning of words and sentences

### Reverse image search
+ Find photos/images similar to input one
+ Remove noises
+ Represent image as *feature vector* (color, shapes, layout, objects, etc)

### Financial fraud detection
+ Determine if transactions, accounts, behaviors, patterns are similar to known fraudulent ones
+ Representation: feature vector/node embedding

# Techniques
## 1. Äá»™ tÆ°Æ¡ng Ä‘á»“ng Jaccard cá»§a cÃ¡c Táº­p há»£p (Jaccard Similarity of Sets)
* **Äá»™ tÆ°Æ¡ng Ä‘á»“ng Jaccard** giá»¯a hai táº­p há»£p $S$ vÃ  $T$ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  tá»‰ lá»‡ giá»¯a kÃ­ch thÆ°á»›c cá»§a pháº§n giao vÃ  kÃ­ch thÆ°á»›c cá»§a pháº§n há»£p.

## 2. Ká»¹ thuáº­t Shingling (Shingling of Documents)
* **K-Shingles:** Äá»‹nh nghÄ©a k-shingle lÃ  báº¥t ká»³ chuá»—i con nÃ o cÃ³ Ä‘á»™ dÃ i k tÃ¬m tháº¥y trong tÃ i liá»‡u.
* **Hashing Shingles:** Sá»­ dá»¥ng hÃ m bÄƒm Ä‘á»ƒ Ã¡nh xáº¡ cÃ¡c chuá»—i dÃ i k nÃ y thÃ nh cÃ¡c sá»‘ bucket ngáº¯n hÆ¡n, giÃºp nÃ©n dá»¯ liá»‡u vÃ  táº¡o Ä‘iá»u kiá»‡n thao tÃ¡c thuáº­n lá»£i hÆ¡n.

## 3. Similarity-Preserving Summaries of Sets
* **Minhashing :** Ká»¹ thuáº­t thay tháº¿ cÃ¡c táº­p há»£p lá»›n báº±ng cÃ¡c biá»ƒu diá»…n nhá» hÆ¡n nhiá»u gá»i lÃ  **"chá»¯ kÃ½" (signatures)**, trong Ä‘Ã³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng Jaccard cá»§a cÃ¡c táº­p há»£p ban Ä‘áº§u cÃ³ thá»ƒ Ä‘Æ°á»£c Æ°á»›c tÃ­nh tá»« chá»¯ kÃ½ cá»§a chÃºng.

## 4. Locality-Sensitive Hashing - LSH for Documents
**LSH** lÃ  má»™t ká»¹ thuáº­t chung Ä‘á»ƒ tÃ¬m cÃ¡c cáº·p má»¥c cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao mÃ  khÃ´ng cáº§n pháº£i kiá»ƒm tra táº¥t cáº£ cÃ¡c cáº·p cÃ³ thá»ƒ.
* **LSH cho Chá»¯ kÃ½ Minhash:** HÃ¬nh thá»©c LSH Ä‘Æ°á»£c thiáº¿t káº¿ cá»¥ thá»ƒ cho cÃ¡c tÃ i liá»‡u Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng chá»¯ kÃ½ Minhash.
* Ká»¹ thuáº­t nÃ y thÆ°á»ng sá»­ dá»¥ng ká»¹ thuáº­t **dáº£i bÄƒng (banding technique)** Ä‘á»ƒ táº¡o ra cÃ¡c **cáº·p á»©ng viÃªn (candidate pairs)**.

## 5. CÃ¡c ThÆ°á»›c Ä‘o Khoáº£ng cÃ¡ch (Distance Measures)
CÃ¡c loáº¡i thÆ°á»›c Ä‘o:

* **Khoáº£ng cÃ¡ch Jaccard (Jaccard Distance):** LÃ  1 trá»« Ä‘i Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng Jaccard.
* **Khoáº£ng cÃ¡ch Euclidean (Euclidean Distances):** ThÆ°á»›c Ä‘o khoáº£ng cÃ¡ch thÃ´ng thÆ°á»ng trong khÃ´ng gian $n$ chiá»u (cÃ²n gá»i lÃ  $L_2$-norm).
* **Khoáº£ng cÃ¡ch Cosine (Cosine Distance):** Äo lÆ°á»ng gÃ³c giá»¯a hai vectÆ¡.
* **Khoáº£ng cÃ¡ch Edit (Edit Distance):** Khoáº£ng cÃ¡ch giá»¯a hai chuá»—i dá»±a trÃªn sá»‘ láº§n chÃ¨n (insertions) vÃ  xÃ³a (deletions) kÃ½ tá»± Ä‘á»ƒ chuyá»ƒn Ä‘á»•i tá»« chuá»—i nÃ y sang chuá»—i kia.
* **Khoáº£ng cÃ¡ch Hamming (Hamming Distance):** Khoáº£ng cÃ¡ch giá»¯a hai vectÆ¡ Boolean hoáº·c bitstrings cÃ³ cÃ¹ng Ä‘á»™ dÃ i, Ä‘áº¿m sá»‘ vá»‹ trÃ­ khÃ¡c nhau.

## 6. LÃ½ thuyáº¿t vá» hÃ m nháº¡y vá»‹ trÃ­ (Theory of Locality-Sensitive Functions)

* Gá»“m cÃ¡c cÃ¡ch khuáº¿ch Ä‘áº¡i má»™t há» hÃ m nháº¡y vá»‹ trÃ­ báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c phÃ©p xÃ¢y dá»±ng **AND** vÃ  **OR** Ä‘á»ƒ Ä‘iá»u chá»‰nh xÃ¡c suáº¥t tÃ¬m ra cÃ¡c cáº·p tÆ°Æ¡ng Ä‘á»“ng.

## 7. LSH cho cÃ¡c thÆ°á»›c Ä‘o khoáº£ng cÃ¡ch khÃ¡c (LSH Families for Other Distance Measures)
* LSH cho **Khoáº£ng cÃ¡ch Hamming**.
* **SiÃªu pháº³ng Ngáº«u nhiÃªn (Random Hyperplanes)** vÃ  LSH cho **Khoáº£ng cÃ¡ch Cosine**.
* LSH cho **Khoáº£ng cÃ¡ch Euclidean**.

## 8. CÃ¡c PhÆ°Æ¡ng phÃ¡p phÃ¡t hiá»‡n má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao (Methods for High Degrees of Similarity)

Khi yÃªu cáº§u vá» má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng ráº¥t cao (gáº§n 1):

* **Lá»c dá»±a trÃªn Äá»™ dÃ i (Length-Based Filtering):** So sÃ¡nh cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ Ä‘á»™ dÃ i (sá»‘ lÆ°á»£ng pháº§n tá»­) gáº§n nhÆ° nhau.
* **Láº­p chá»‰ má»¥c Tiá»n tá»‘ (Prefix Indexing):** Sá»­ dá»¥ng cÃ¡c kÃ½ hiá»‡u á»Ÿ Ä‘áº§u (tiá»n tá»‘) cá»§a chuá»—i Ä‘á»ƒ xÃ¢y dá»±ng chá»‰ má»¥c vÃ  giáº£m sá»‘ lÆ°á»£ng so sÃ¡nh cáº§n thiáº¿t.
* Sá»­ dá»¥ng thÃ´ng tin **Vá»‹ trÃ­** vÃ  **Äá»™ dÃ i Háº­u tá»‘ (Suffix Length):** Cáº£i tiáº¿n viá»‡c láº­p chá»‰ má»¥c báº±ng cÃ¡ch xÃ©t cáº£ vá»‹ trÃ­ cá»§a kÃ½ hiá»‡u trong tiá»n tá»‘ vÃ  Ä‘á»™ dÃ i cá»§a pháº§n cÃ²n láº¡i cá»§a chuá»—i.

